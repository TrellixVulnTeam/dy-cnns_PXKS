Using downloaded and verified file: ./data/cifar10_trainval_F21.zip
Extracting ./data/cifar10_trainval_F21.zip to ./data
Files already downloaded and verified
Using downloaded and verified file: ./data/cifar10_trainval_F21.zip
Extracting ./data/cifar10_trainval_F21.zip to ./data
Files already downloaded and verified
Using downloaded and verified file: ./data/cifar10_test_F21.zip
Extracting ./data/cifar10_test_F21.zip to ./data
Files already downloaded and verified
45000
iter num  450
Using device: cuda:0
==> Training starts!
==================================================

Epoch [1/160]
Epoch 1:
Training loss: 666.2303, Training accuracy: 0.1919
Validation loss: 1.9047, Validation accuracy: 0.2672
Saving ...


Epoch [2/160]
Epoch 2:
Training loss: 665.8293, Training accuracy: 0.3429
Validation loss: 1.6003, Validation accuracy: 0.4032
Saving ...


Epoch [3/160]
Epoch 3:
Training loss: 665.6487, Training accuracy: 0.4276
Validation loss: 1.4609, Validation accuracy: 0.4612
Saving ...


Epoch [4/160]
Epoch 4:
Training loss: 665.5247, Training accuracy: 0.4804
Validation loss: 1.3370, Validation accuracy: 0.5088
Saving ...


Epoch [5/160]
Epoch 5:
Training loss: 665.4329, Training accuracy: 0.5177
Validation loss: 1.3591, Validation accuracy: 0.5130
Saving ...


Epoch [6/160]
Epoch 6:
Training loss: 665.3774, Training accuracy: 0.5406
Validation loss: 1.2356, Validation accuracy: 0.5580
Saving ...


Epoch [7/160]
Epoch 7:
Training loss: 665.3254, Training accuracy: 0.5632
Validation loss: 1.2123, Validation accuracy: 0.5658
Saving ...


Epoch [8/160]
Epoch 8:
Training loss: 665.2849, Training accuracy: 0.5771
Validation loss: 1.1677, Validation accuracy: 0.5836
Saving ...


Epoch [9/160]
Epoch 9:
Training loss: 665.2479, Training accuracy: 0.5904
Validation loss: 1.2823, Validation accuracy: 0.5490


Epoch [10/160]
Epoch 10:
Training loss: 665.2208, Training accuracy: 0.6028
Validation loss: 1.0663, Validation accuracy: 0.6210
Saving ...


Epoch [11/160]
Epoch 11:
Training loss: 665.1956, Training accuracy: 0.6140
Validation loss: 1.2255, Validation accuracy: 0.5794


Epoch [12/160]
Epoch 12:
Training loss: 665.1746, Training accuracy: 0.6196
Validation loss: 1.0767, Validation accuracy: 0.6200


Epoch [13/160]
Epoch 13:
Training loss: 665.1559, Training accuracy: 0.6301
Validation loss: 1.2046, Validation accuracy: 0.5908


Epoch [14/160]
Epoch 14:
Training loss: 665.1440, Training accuracy: 0.6339
Validation loss: 1.4232, Validation accuracy: 0.5400


Epoch [15/160]
Epoch 15:
Training loss: 665.1255, Training accuracy: 0.6416
Validation loss: 1.0716, Validation accuracy: 0.6246
Saving ...


Epoch [16/160]
Epoch 16:
Training loss: 665.1129, Training accuracy: 0.6426
Validation loss: 1.0065, Validation accuracy: 0.6482
Saving ...


Epoch [17/160]
Epoch 17:
Training loss: 665.0970, Training accuracy: 0.6508
Validation loss: 1.0844, Validation accuracy: 0.6200


Epoch [18/160]
Epoch 18:
Training loss: 665.0904, Training accuracy: 0.6531
Validation loss: 0.9706, Validation accuracy: 0.6514
Saving ...


Epoch [19/160]
Epoch 19:
Training loss: 665.0716, Training accuracy: 0.6609
Validation loss: 0.9902, Validation accuracy: 0.6494


Epoch [20/160]
Epoch 20:
Training loss: 665.0645, Training accuracy: 0.6612
Validation loss: 1.0478, Validation accuracy: 0.6360


Epoch [21/160]
Epoch 21:
Training loss: 665.0569, Training accuracy: 0.6660
Validation loss: 1.1555, Validation accuracy: 0.6118


Epoch [22/160]
Epoch 22:
Training loss: 665.0463, Training accuracy: 0.6696
Validation loss: 0.9811, Validation accuracy: 0.6682
Saving ...


Epoch [23/160]
Epoch 23:
Training loss: 665.0347, Training accuracy: 0.6731
Validation loss: 1.0288, Validation accuracy: 0.6512


Epoch [24/160]
Epoch 24:
Training loss: 665.0272, Training accuracy: 0.6768
Validation loss: 0.9278, Validation accuracy: 0.6808
Saving ...


Epoch [25/160]
Epoch 25:
Training loss: 665.0180, Training accuracy: 0.6812
Validation loss: 1.0981, Validation accuracy: 0.6434


Epoch [26/160]
Epoch 26:
Training loss: 665.0143, Training accuracy: 0.6812
Validation loss: 0.9963, Validation accuracy: 0.6656


Epoch [27/160]
Epoch 27:
Training loss: 665.0074, Training accuracy: 0.6837
Validation loss: 0.9795, Validation accuracy: 0.6558


Epoch [28/160]
Epoch 28:
Training loss: 664.9976, Training accuracy: 0.6884
Validation loss: 0.9467, Validation accuracy: 0.6686


Epoch [29/160]
Epoch 29:
Training loss: 664.9892, Training accuracy: 0.6911
Validation loss: 0.9181, Validation accuracy: 0.6762


Epoch [30/160]
Epoch 30:
Training loss: 664.9907, Training accuracy: 0.6906
Validation loss: 1.0865, Validation accuracy: 0.6368


Epoch [31/160]
Epoch 31:
Training loss: 664.9855, Training accuracy: 0.6929
Validation loss: 0.9483, Validation accuracy: 0.6832
Saving ...


Epoch [32/160]
Epoch 32:
Training loss: 664.9772, Training accuracy: 0.6959
Validation loss: 0.9843, Validation accuracy: 0.6682


Epoch [33/160]
Epoch 33:
Training loss: 664.9758, Training accuracy: 0.6958
Validation loss: 0.9081, Validation accuracy: 0.6858
Saving ...


Epoch [34/160]
Epoch 34:
Training loss: 664.9662, Training accuracy: 0.7007
Validation loss: 0.8935, Validation accuracy: 0.6928
Saving ...


Epoch [35/160]
Epoch 35:
Training loss: 664.9652, Training accuracy: 0.6965
Validation loss: 0.8816, Validation accuracy: 0.6856


Epoch [36/160]
Epoch 36:
Training loss: 664.9606, Training accuracy: 0.7025
Validation loss: 0.9805, Validation accuracy: 0.6608


Epoch [37/160]
Epoch 37:
Training loss: 664.9535, Training accuracy: 0.7032
Validation loss: 0.9894, Validation accuracy: 0.6664


Epoch [38/160]
Epoch 38:
Training loss: 664.9523, Training accuracy: 0.7031
Validation loss: 1.1179, Validation accuracy: 0.6340


Epoch [39/160]
Epoch 39:
Training loss: 664.9487, Training accuracy: 0.7034
Validation loss: 0.9775, Validation accuracy: 0.6702


Epoch [40/160]
Epoch 40:
Training loss: 664.9539, Training accuracy: 0.7044
Validation loss: 0.9484, Validation accuracy: 0.6754


Epoch [41/160]
Epoch 41:
Training loss: 664.9438, Training accuracy: 0.7086
Validation loss: 0.9755, Validation accuracy: 0.6690


Epoch [42/160]
Epoch 42:
Training loss: 664.9401, Training accuracy: 0.7092
Validation loss: 0.9425, Validation accuracy: 0.6764


Epoch [43/160]
Epoch 43:
Training loss: 664.9355, Training accuracy: 0.7106
Validation loss: 0.9063, Validation accuracy: 0.6882


Epoch [44/160]
Epoch 44:
Training loss: 664.9368, Training accuracy: 0.7099
Validation loss: 0.9850, Validation accuracy: 0.6582
Epoch    44: reducing learning rate of group 0 to 1.0000e-02.


Epoch [45/160]
Epoch 45:
Training loss: 664.8561, Training accuracy: 0.7424
Validation loss: 0.7422, Validation accuracy: 0.7418
Saving ...


Epoch [46/160]
Epoch 46:
Training loss: 664.8344, Training accuracy: 0.7491
Validation loss: 0.7210, Validation accuracy: 0.7504
Saving ...


Epoch [47/160]
Epoch 47:
Training loss: 664.8273, Training accuracy: 0.7493
Validation loss: 0.7308, Validation accuracy: 0.7476


Epoch [48/160]
Epoch 48:
Training loss: 664.8277, Training accuracy: 0.7472
Validation loss: 0.7259, Validation accuracy: 0.7450


Epoch [49/160]
Epoch 49:
Training loss: 664.8163, Training accuracy: 0.7560
Validation loss: 0.7355, Validation accuracy: 0.7412


Epoch [50/160]
Epoch 50:
Training loss: 664.8149, Training accuracy: 0.7542
Validation loss: 0.7126, Validation accuracy: 0.7550
Saving ...


Epoch [51/160]
Epoch 51:
Training loss: 664.8175, Training accuracy: 0.7532
Validation loss: 0.7272, Validation accuracy: 0.7496


Epoch [52/160]
Epoch 52:
Training loss: 664.8119, Training accuracy: 0.7556
Validation loss: 0.7388, Validation accuracy: 0.7454


Epoch [53/160]
Epoch 53:
Training loss: 664.8087, Training accuracy: 0.7578
Validation loss: 0.7138, Validation accuracy: 0.7536


Epoch [54/160]
Epoch 54:
Training loss: 664.8087, Training accuracy: 0.7574
Validation loss: 0.7269, Validation accuracy: 0.7512


Epoch [55/160]
Epoch 55:
Training loss: 664.8049, Training accuracy: 0.7579
Validation loss: 0.7244, Validation accuracy: 0.7500


Epoch [56/160]
Epoch 56:
Training loss: 664.8052, Training accuracy: 0.7577
Validation loss: 0.7123, Validation accuracy: 0.7552
Saving ...


Epoch [57/160]
Epoch 57:
Training loss: 664.8012, Training accuracy: 0.7586
Validation loss: 0.7141, Validation accuracy: 0.7476


Epoch [58/160]
Epoch 58:
Training loss: 664.8051, Training accuracy: 0.7586
Validation loss: 0.7266, Validation accuracy: 0.7520


Epoch [59/160]
Epoch 59:
Training loss: 664.8011, Training accuracy: 0.7616
Validation loss: 0.7181, Validation accuracy: 0.7494


Epoch [60/160]
Epoch 60:
Training loss: 664.7977, Training accuracy: 0.7598
Validation loss: 0.7112, Validation accuracy: 0.7538


Epoch [61/160]
Epoch 61:
Training loss: 664.7992, Training accuracy: 0.7616
Validation loss: 0.7027, Validation accuracy: 0.7520


Epoch [62/160]
Epoch 62:
Training loss: 664.7961, Training accuracy: 0.7601
Validation loss: 0.7066, Validation accuracy: 0.7548


Epoch [63/160]
Epoch 63:
Training loss: 664.7993, Training accuracy: 0.7592
Validation loss: 0.6973, Validation accuracy: 0.7584
Saving ...


Epoch [64/160]
Epoch 64:
Training loss: 664.7973, Training accuracy: 0.7601
Validation loss: 0.6943, Validation accuracy: 0.7592
Saving ...


Epoch [65/160]
Epoch 65:
Training loss: 664.7908, Training accuracy: 0.7634
Validation loss: 0.7272, Validation accuracy: 0.7520


Epoch [66/160]
Epoch 66:
Training loss: 664.7906, Training accuracy: 0.7626
Validation loss: 0.7398, Validation accuracy: 0.7454


Epoch [67/160]
Epoch 67:
Training loss: 664.7928, Training accuracy: 0.7618
Validation loss: 0.6970, Validation accuracy: 0.7572


Epoch [68/160]
Epoch 68:
Training loss: 664.7892, Training accuracy: 0.7617
Validation loss: 0.7087, Validation accuracy: 0.7560


Epoch [69/160]
Epoch 69:
Training loss: 664.7885, Training accuracy: 0.7626
Validation loss: 0.7069, Validation accuracy: 0.7596
Saving ...


Epoch [70/160]
Epoch 70:
Training loss: 664.7886, Training accuracy: 0.7652
Validation loss: 0.6907, Validation accuracy: 0.7646
Saving ...


Epoch [71/160]
Epoch 71:
Training loss: 664.7905, Training accuracy: 0.7636
Validation loss: 0.7112, Validation accuracy: 0.7576


Epoch [72/160]
Epoch 72:
Training loss: 664.7897, Training accuracy: 0.7613
Validation loss: 0.7173, Validation accuracy: 0.7534


Epoch [73/160]
Epoch 73:
Training loss: 664.7875, Training accuracy: 0.7616
Validation loss: 0.7139, Validation accuracy: 0.7536


Epoch [74/160]
Epoch 74:
Training loss: 664.7859, Training accuracy: 0.7644
Validation loss: 0.7131, Validation accuracy: 0.7580


Epoch [75/160]
Epoch 75:
Training loss: 664.7863, Training accuracy: 0.7644
Validation loss: 0.7003, Validation accuracy: 0.7616


Epoch [76/160]
Epoch 76:
Training loss: 664.7874, Training accuracy: 0.7650
Validation loss: 0.7263, Validation accuracy: 0.7514


Epoch [77/160]
Epoch 77:
Training loss: 664.7840, Training accuracy: 0.7638
Validation loss: 0.7166, Validation accuracy: 0.7548


Epoch [78/160]
Epoch 78:
Training loss: 664.7808, Training accuracy: 0.7677
Validation loss: 0.6993, Validation accuracy: 0.7634


Epoch [79/160]
Epoch 79:
Training loss: 664.7831, Training accuracy: 0.7656
Validation loss: 0.6984, Validation accuracy: 0.7610
Epoch    79: reducing learning rate of group 0 to 1.0000e-03.


Epoch [80/160]
Epoch 80:
Training loss: 664.7665, Training accuracy: 0.7729
Validation loss: 0.6742, Validation accuracy: 0.7710
Saving ...


Epoch [81/160]
Epoch 81:
Training loss: 664.7651, Training accuracy: 0.7720
Validation loss: 0.6743, Validation accuracy: 0.7680


Epoch [82/160]
Epoch 82:
Training loss: 664.7590, Training accuracy: 0.7760
Validation loss: 0.6748, Validation accuracy: 0.7710


Epoch [83/160]
Epoch 83:
Training loss: 664.7607, Training accuracy: 0.7727
Validation loss: 0.6745, Validation accuracy: 0.7690


Epoch [84/160]
Epoch 84:
Training loss: 664.7601, Training accuracy: 0.7764
Validation loss: 0.6721, Validation accuracy: 0.7704


Epoch [85/160]
Epoch 85:
Training loss: 664.7596, Training accuracy: 0.7743
Validation loss: 0.6709, Validation accuracy: 0.7702


Epoch [86/160]
Epoch 86:
Training loss: 664.7571, Training accuracy: 0.7756
Validation loss: 0.6726, Validation accuracy: 0.7724
Saving ...


Epoch [87/160]
Epoch 87:
Training loss: 664.7592, Training accuracy: 0.7743
Validation loss: 0.6697, Validation accuracy: 0.7690


Epoch [88/160]
Epoch 88:
Training loss: 664.7599, Training accuracy: 0.7740
Validation loss: 0.6730, Validation accuracy: 0.7724


Epoch [89/160]
Epoch 89:
Training loss: 664.7576, Training accuracy: 0.7758
Validation loss: 0.6697, Validation accuracy: 0.7722


Epoch [90/160]
Epoch 90:
Training loss: 664.7542, Training accuracy: 0.7778
Validation loss: 0.6708, Validation accuracy: 0.7728
Saving ...


Epoch [91/160]
Epoch 91:
Training loss: 664.7608, Training accuracy: 0.7739
Validation loss: 0.6721, Validation accuracy: 0.7718


Epoch [92/160]
Epoch 92:
Training loss: 664.7586, Training accuracy: 0.7763
Validation loss: 0.6732, Validation accuracy: 0.7722


Epoch [93/160]
Epoch 93:
Training loss: 664.7563, Training accuracy: 0.7750
Validation loss: 0.6691, Validation accuracy: 0.7704


Epoch [94/160]
Epoch 94:
Training loss: 664.7595, Training accuracy: 0.7761
Validation loss: 0.6690, Validation accuracy: 0.7724


Epoch [95/160]
Epoch 95:
Training loss: 664.7545, Training accuracy: 0.7744
Validation loss: 0.6712, Validation accuracy: 0.7724


Epoch [96/160]
Epoch 96:
Training loss: 664.7573, Training accuracy: 0.7771
Validation loss: 0.6667, Validation accuracy: 0.7740
Saving ...


Epoch [97/160]
Epoch 97:
Training loss: 664.7524, Training accuracy: 0.7774
Validation loss: 0.6712, Validation accuracy: 0.7714


Epoch [98/160]
Epoch 98:
Training loss: 664.7578, Training accuracy: 0.7747
Validation loss: 0.6675, Validation accuracy: 0.7728


Epoch [99/160]
Epoch 99:
Training loss: 664.7518, Training accuracy: 0.7781
Validation loss: 0.6703, Validation accuracy: 0.7742
Saving ...


Epoch [100/160]
Epoch 100:
Training loss: 664.7570, Training accuracy: 0.7757
Validation loss: 0.6654, Validation accuracy: 0.7724


Epoch [101/160]
Epoch 101:
Training loss: 664.7580, Training accuracy: 0.7754
Validation loss: 0.6702, Validation accuracy: 0.7708


Epoch [102/160]
Epoch 102:
Training loss: 664.7570, Training accuracy: 0.7758
Validation loss: 0.6653, Validation accuracy: 0.7758
Saving ...


Epoch [103/160]
Epoch 103:
Training loss: 664.7562, Training accuracy: 0.7756
Validation loss: 0.6665, Validation accuracy: 0.7768
Saving ...


Epoch [104/160]
Epoch 104:
Training loss: 664.7535, Training accuracy: 0.7764
Validation loss: 0.6715, Validation accuracy: 0.7716


Epoch [105/160]
Epoch 105:
Training loss: 664.7559, Training accuracy: 0.7735
Validation loss: 0.6704, Validation accuracy: 0.7706


Epoch [106/160]
Epoch 106:
Training loss: 664.7550, Training accuracy: 0.7767
Validation loss: 0.6743, Validation accuracy: 0.7694


Epoch [107/160]
Epoch 107:
Training loss: 664.7498, Training accuracy: 0.7773
Validation loss: 0.6684, Validation accuracy: 0.7742


Epoch [108/160]
Epoch 108:
Training loss: 664.7535, Training accuracy: 0.7772
Validation loss: 0.6672, Validation accuracy: 0.7738


Epoch [109/160]
Epoch 109:
Training loss: 664.7543, Training accuracy: 0.7771
Validation loss: 0.6689, Validation accuracy: 0.7710


Epoch [110/160]
Epoch 110:
Training loss: 664.7512, Training accuracy: 0.7777
Validation loss: 0.6662, Validation accuracy: 0.7718


Epoch [111/160]
Epoch 111:
Training loss: 664.7516, Training accuracy: 0.7776
Validation loss: 0.6687, Validation accuracy: 0.7694
Epoch   111: reducing learning rate of group 0 to 1.0000e-04.


Epoch [112/160]
Epoch 112:
Training loss: 664.7540, Training accuracy: 0.7752
Validation loss: 0.6662, Validation accuracy: 0.7744


Epoch [113/160]
Epoch 113:
Training loss: 664.7519, Training accuracy: 0.7759
Validation loss: 0.6640, Validation accuracy: 0.7764


Epoch [114/160]
Epoch 114:
Training loss: 664.7518, Training accuracy: 0.7758
Validation loss: 0.6657, Validation accuracy: 0.7750


Epoch [115/160]
Epoch 115:
Training loss: 664.7489, Training accuracy: 0.7777
Validation loss: 0.6615, Validation accuracy: 0.7754


Epoch [116/160]
Epoch 116:
Training loss: 664.7502, Training accuracy: 0.7785
Validation loss: 0.6608, Validation accuracy: 0.7770
Saving ...


Epoch [117/160]
Epoch 117:
Training loss: 664.7523, Training accuracy: 0.7764
Validation loss: 0.6630, Validation accuracy: 0.7728


Epoch [118/160]
Epoch 118:
Training loss: 664.7511, Training accuracy: 0.7785
Validation loss: 0.6681, Validation accuracy: 0.7708


Epoch [119/160]
Epoch 119:
Training loss: 664.7482, Training accuracy: 0.7785
Validation loss: 0.6670, Validation accuracy: 0.7736


Epoch [120/160]
Epoch 120:
Training loss: 664.7493, Training accuracy: 0.7776
Validation loss: 0.6677, Validation accuracy: 0.7760


Epoch [121/160]
Epoch 121:
Training loss: 664.7510, Training accuracy: 0.7774
Validation loss: 0.6664, Validation accuracy: 0.7736


Epoch [122/160]
Epoch 122:
Training loss: 664.7528, Training accuracy: 0.7775
Validation loss: 0.6637, Validation accuracy: 0.7784
Saving ...


Epoch [123/160]
Epoch 123:
Training loss: 664.7476, Training accuracy: 0.7779
Validation loss: 0.6672, Validation accuracy: 0.7728


Epoch [124/160]
Epoch 124:
Training loss: 664.7496, Training accuracy: 0.7770
Validation loss: 0.6633, Validation accuracy: 0.7772


Epoch [125/160]
Epoch 125:
Training loss: 664.7507, Training accuracy: 0.7785
Validation loss: 0.6683, Validation accuracy: 0.7754
Epoch   125: reducing learning rate of group 0 to 1.0000e-05.


Epoch [126/160]
Epoch 126:
Training loss: 664.7464, Training accuracy: 0.7792
Validation loss: 0.6667, Validation accuracy: 0.7708


Epoch [127/160]
Epoch 127:
Training loss: 664.7491, Training accuracy: 0.7778
Validation loss: 0.6707, Validation accuracy: 0.7728


Epoch [128/160]
Epoch 128:
Training loss: 664.7512, Training accuracy: 0.7769
Validation loss: 0.6670, Validation accuracy: 0.7724


Epoch [129/160]
Epoch 129:
Training loss: 664.7493, Training accuracy: 0.7772
Validation loss: 0.6689, Validation accuracy: 0.7732


Epoch [130/160]
Epoch 130:
Training loss: 664.7482, Training accuracy: 0.7803
Validation loss: 0.6640, Validation accuracy: 0.7782


Epoch [131/160]
Epoch 131:
Training loss: 664.7460, Training accuracy: 0.7797
Validation loss: 0.6640, Validation accuracy: 0.7750


Epoch [132/160]
Epoch 132:
Training loss: 664.7511, Training accuracy: 0.7779
Validation loss: 0.6644, Validation accuracy: 0.7752


Epoch [133/160]
Epoch 133:
Training loss: 664.7490, Training accuracy: 0.7782
Validation loss: 0.6649, Validation accuracy: 0.7748


Epoch [134/160]
Epoch 134:
Training loss: 664.7474, Training accuracy: 0.7804
Validation loss: 0.6673, Validation accuracy: 0.7762
Epoch   134: reducing learning rate of group 0 to 1.0000e-06.


Epoch [135/160]
Epoch 135:
Training loss: 664.7477, Training accuracy: 0.7786
Validation loss: 0.6636, Validation accuracy: 0.7766


Epoch [136/160]
Epoch 136:
Training loss: 664.7517, Training accuracy: 0.7774
Validation loss: 0.6617, Validation accuracy: 0.7762


Epoch [137/160]
Epoch 137:
Training loss: 664.7490, Training accuracy: 0.7779
Validation loss: 0.6637, Validation accuracy: 0.7736


Epoch [138/160]
Epoch 138:
Training loss: 664.7496, Training accuracy: 0.7780
Validation loss: 0.6669, Validation accuracy: 0.7718


Epoch [139/160]
Epoch 139:
Training loss: 664.7515, Training accuracy: 0.7778
Validation loss: 0.6635, Validation accuracy: 0.7752


Epoch [140/160]
Epoch 140:
Training loss: 664.7480, Training accuracy: 0.7787
Validation loss: 0.6648, Validation accuracy: 0.7754


Epoch [141/160]
Epoch 141:
Training loss: 664.7493, Training accuracy: 0.7766
Validation loss: 0.6626, Validation accuracy: 0.7764


Epoch [142/160]
Epoch 142:
Training loss: 664.7511, Training accuracy: 0.7774
Validation loss: 0.6675, Validation accuracy: 0.7744


Epoch [143/160]
Epoch 143:
Training loss: 664.7507, Training accuracy: 0.7767
Validation loss: 0.6640, Validation accuracy: 0.7762
Epoch   143: reducing learning rate of group 0 to 1.0000e-07.


Epoch [144/160]
Epoch 144:
Training loss: 664.7487, Training accuracy: 0.7787
Validation loss: 0.6665, Validation accuracy: 0.7738


Epoch [145/160]
Epoch 145:
Training loss: 664.7488, Training accuracy: 0.7789
Validation loss: 0.6662, Validation accuracy: 0.7728


Epoch [146/160]
Epoch 146:
Training loss: 664.7495, Training accuracy: 0.7780
Validation loss: 0.6637, Validation accuracy: 0.7726


Epoch [147/160]
Epoch 147:
Training loss: 664.7495, Training accuracy: 0.7779
Validation loss: 0.6667, Validation accuracy: 0.7732


Epoch [148/160]
Epoch 148:
Training loss: 664.7490, Training accuracy: 0.7756
Validation loss: 0.6642, Validation accuracy: 0.7720


Epoch [149/160]
Epoch 149:
Training loss: 664.7491, Training accuracy: 0.7784
Validation loss: 0.6651, Validation accuracy: 0.7782


Epoch [150/160]
Epoch 150:
Training loss: 664.7479, Training accuracy: 0.7798
Validation loss: 0.6647, Validation accuracy: 0.7746


Epoch [151/160]
Epoch 151:
Training loss: 664.7511, Training accuracy: 0.7767
Validation loss: 0.6607, Validation accuracy: 0.7742


Epoch [152/160]
Epoch 152:
Training loss: 664.7482, Training accuracy: 0.7787
Validation loss: 0.6664, Validation accuracy: 0.7748


Epoch [153/160]
Epoch 153:
Training loss: 664.7504, Training accuracy: 0.7790
Validation loss: 0.6669, Validation accuracy: 0.7744


Epoch [154/160]
Epoch 154:
Training loss: 664.7523, Training accuracy: 0.7755
Validation loss: 0.6629, Validation accuracy: 0.7748


Epoch [155/160]
Epoch 155:
Training loss: 664.7473, Training accuracy: 0.7794
Validation loss: 0.6637, Validation accuracy: 0.7728


Epoch [156/160]
Epoch 156:
Training loss: 664.7490, Training accuracy: 0.7772
Validation loss: 0.6669, Validation accuracy: 0.7740


Epoch [157/160]
Epoch 157:
Training loss: 664.7522, Training accuracy: 0.7782
Validation loss: 0.6678, Validation accuracy: 0.7716


Epoch [158/160]
Epoch 158:
Training loss: 664.7474, Training accuracy: 0.7774
Validation loss: 0.6691, Validation accuracy: 0.7746


Epoch [159/160]
Epoch 159:
Training loss: 664.7523, Training accuracy: 0.7776
Validation loss: 0.6649, Validation accuracy: 0.7736


Epoch [160/160]
Epoch 160:
Training loss: 664.7509, Training accuracy: 0.7763
Validation loss: 0.6669, Validation accuracy: 0.7744
Epoch   160: reducing learning rate of group 0 to 1.0000e-08.

==================================================
==> Optimization finished! Best validation accuracy: 0.7784
Validation loss: 0.6659, Validation accuracy: 0.7738
block1[0].gate
batch_size = 5000, gate_um = 16
on = 0, off = 0, rest = 16
on = 0.00%, off = 0.00%, rest = 100.00%
block1[1].gate
batch_size = 5000, gate_um = 16
on = 0, off = 0, rest = 16
on = 0.00%, off = 0.00%, rest = 100.00%
block1[2].gate
batch_size = 5000, gate_um = 16
on = 0, off = 0, rest = 16
on = 0.00%, off = 0.00%, rest = 100.00%
block2[0].gate
batch_size = 5000, gate_um = 32
on = 0, off = 2, rest = 30
on = 0.00%, off = 6.25%, rest = 93.75%
block2[1].gate
batch_size = 5000, gate_um = 32
on = 0, off = 3, rest = 29
on = 0.00%, off = 9.38%, rest = 90.62%
block2[2].gate
batch_size = 5000, gate_um = 32
on = 0, off = 10, rest = 22
on = 0.00%, off = 31.25%, rest = 68.75%
block3[0].gate
batch_size = 5000, gate_um = 64
on = 0, off = 23, rest = 41
on = 0.00%, off = 35.94%, rest = 64.06%
block3[1].gate
batch_size = 5000, gate_um = 64
on = 0, off = 14, rest = 50
on = 0.00%, off = 21.88%, rest = 78.12%
block3[2].gate
batch_size = 5000, gate_um = 64
on = 0, off = 18, rest = 46
on = 0.00%, off = 28.12%, rest = 71.88%
